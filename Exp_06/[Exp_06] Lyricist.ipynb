{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d990e004",
   "metadata": {},
   "source": [
    "### Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d108c0",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7767bb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = '/aiffel/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = [] \n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba7a2995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I've heard there was a secret chord\n",
      "That David played, and it pleased the Lord\n",
      "But you don't really care for music, do you?\n",
      "It goes like this\n",
      "The fourth, the fifth\n",
      "The minor fall, the major lift\n",
      "The baffled king composing Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah Your faith was strong but you needed proof\n"
     ]
    }
   ],
   "source": [
    "# enumerate() 함수를 이용하여 raw_corpus list 내에 저장된 문장과 그 문장의 인덱스를 반환 (인덱스, 문장 순)\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 : 인 문장은 건너뜁니다.\n",
    "\n",
    "    if idx > 9: break   # 문장 10개만 확인\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe151cc",
   "metadata": {},
   "source": [
    "### Step 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b346933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e746da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>',\n",
       " '<start> you saw her bathing on the roof <end>',\n",
       " '<start> her beauty and the moonlight overthrew her <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if len(sentence.split(' ')) <= 1: continue\n",
    "    if len(sentence.split(' ')) > 15: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82603e0",
   "metadata": {},
   "source": [
    "### Step 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d32116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093258be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    5 ...    0    0    0]\n",
      " [   2   17 2686 ...    0    0    0]\n",
      " [   2   34    7 ...    0    0    0]\n",
      " ...\n",
      " [   2  258  193 ...    0    0    0]\n",
      " [   2  132    5 ...    0    0    0]\n",
      " [   2    7   33 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7fb88ceb59a0>\n"
     ]
    }
   ],
   "source": [
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f96ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    5   91  306   62   57    9  952 5678    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "[  50    5   91  306   62   57    9  952 5678    3    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c292f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                          tgt_input,\n",
    "                                          test_size = 0.2,\n",
    "                                          random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5a703",
   "metadata": {},
   "source": [
    "### Step 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe7d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 32), (256, 32)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29034c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13c69ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 32, 12001), dtype=float32, numpy=\n",
       "array([[[-1.72430682e-05,  2.67380506e-06,  5.17131703e-05, ...,\n",
       "          5.23548260e-05, -5.34188584e-05, -1.98627295e-05],\n",
       "        [ 1.41809127e-04, -2.26052507e-04, -1.61259431e-05, ...,\n",
       "          1.09075678e-04, -1.04522820e-04, -1.14310140e-04],\n",
       "        [ 2.65123323e-04, -4.68807557e-04,  8.91174350e-05, ...,\n",
       "         -5.62138564e-04,  3.19409664e-05, -8.05863965e-05],\n",
       "        ...,\n",
       "        [ 4.44197183e-04, -1.24111166e-03,  1.56346976e-03, ...,\n",
       "         -4.01407434e-03,  1.94797688e-03, -6.13773195e-03],\n",
       "        [ 4.35811002e-04, -1.26229285e-03,  1.57259626e-03, ...,\n",
       "         -4.06635227e-03,  1.97261502e-03, -6.17369637e-03],\n",
       "        [ 4.28528845e-04, -1.28011953e-03,  1.58036838e-03, ...,\n",
       "         -4.11162479e-03,  1.99474767e-03, -6.20317180e-03]],\n",
       "\n",
       "       [[-1.72430682e-05,  2.67380506e-06,  5.17131703e-05, ...,\n",
       "          5.23548260e-05, -5.34188584e-05, -1.98627295e-05],\n",
       "        [-1.13755443e-04,  1.23755308e-04,  2.50649144e-04, ...,\n",
       "          1.29838198e-04, -1.32295654e-05,  8.87227943e-05],\n",
       "        [-5.71488054e-05,  5.38107561e-05,  3.13285680e-04, ...,\n",
       "          2.54883082e-04, -2.25899828e-04,  2.00250171e-04],\n",
       "        ...,\n",
       "        [ 4.89958096e-04, -1.01543369e-03,  1.37393794e-03, ...,\n",
       "         -3.38333589e-03,  1.88887434e-03, -5.59037365e-03],\n",
       "        [ 4.74855246e-04, -1.06214627e-03,  1.40657381e-03, ...,\n",
       "         -3.49892443e-03,  1.89860689e-03, -5.70929935e-03],\n",
       "        [ 4.62537864e-04, -1.10361364e-03,  1.43407797e-03, ...,\n",
       "         -3.60502792e-03,  1.90991012e-03, -5.81077905e-03]],\n",
       "\n",
       "       [[-1.72430682e-05,  2.67380506e-06,  5.17131703e-05, ...,\n",
       "          5.23548260e-05, -5.34188584e-05, -1.98627295e-05],\n",
       "        [-3.91240465e-05,  1.13051748e-04,  1.62844692e-04, ...,\n",
       "          2.33089653e-04, -1.56425056e-04, -8.61843364e-05],\n",
       "        [-1.12508105e-05,  3.13622331e-05,  9.27734291e-05, ...,\n",
       "          2.17205437e-04, -4.59136529e-04,  2.35174248e-05],\n",
       "        ...,\n",
       "        [ 4.10700217e-04, -1.32317026e-03,  1.56993628e-03, ...,\n",
       "         -4.03339555e-03,  1.92073942e-03, -6.25244481e-03],\n",
       "        [ 4.06120729e-04, -1.33123854e-03,  1.57407485e-03, ...,\n",
       "         -4.08295402e-03,  1.95019785e-03, -6.27103169e-03],\n",
       "        [ 4.01985162e-04, -1.33771054e-03,  1.57814287e-03, ...,\n",
       "         -4.12591314e-03,  1.97637221e-03, -6.28542667e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.72430682e-05,  2.67380506e-06,  5.17131703e-05, ...,\n",
       "          5.23548260e-05, -5.34188584e-05, -1.98627295e-05],\n",
       "        [-1.16616597e-04, -5.55254956e-05, -9.03374312e-05, ...,\n",
       "          1.76478658e-04, -4.33947534e-05, -6.63369865e-05],\n",
       "        [-7.49860992e-05, -6.68335124e-05, -1.41621844e-04, ...,\n",
       "         -1.64581317e-04, -3.10966629e-04, -1.88366175e-04],\n",
       "        ...,\n",
       "        [ 6.57882541e-04, -9.03148321e-04,  1.28592213e-03, ...,\n",
       "         -2.70650024e-03,  1.14978035e-03, -4.94149420e-03],\n",
       "        [ 6.10488409e-04, -9.84235900e-04,  1.33642124e-03, ...,\n",
       "         -2.88718520e-03,  1.26981235e-03, -5.15583484e-03],\n",
       "        [ 5.69839438e-04, -1.05487276e-03,  1.37891190e-03, ...,\n",
       "         -3.05539905e-03,  1.37521874e-03, -5.34090865e-03]],\n",
       "\n",
       "       [[-1.72430682e-05,  2.67380506e-06,  5.17131703e-05, ...,\n",
       "          5.23548260e-05, -5.34188584e-05, -1.98627295e-05],\n",
       "        [-1.86783756e-04,  2.38132270e-04,  4.82737931e-04, ...,\n",
       "          1.78813825e-05, -2.91269796e-04,  2.29991012e-04],\n",
       "        [-3.83568782e-04,  4.86816600e-04,  6.51525683e-04, ...,\n",
       "          1.15685551e-04, -5.05750242e-04,  3.52632254e-04],\n",
       "        ...,\n",
       "        [ 4.16925497e-04, -1.29815144e-03,  1.60409324e-03, ...,\n",
       "         -4.03079716e-03,  1.88972545e-03, -6.16552681e-03],\n",
       "        [ 4.10821405e-04, -1.30971160e-03,  1.60436681e-03, ...,\n",
       "         -4.08180337e-03,  1.92180823e-03, -6.19932869e-03],\n",
       "        [ 4.05578350e-04, -1.31940178e-03,  1.60485890e-03, ...,\n",
       "         -4.12583211e-03,  1.95059029e-03, -6.22665882e-03]],\n",
       "\n",
       "       [[-1.72430682e-05,  2.67380506e-06,  5.17131703e-05, ...,\n",
       "          5.23548260e-05, -5.34188584e-05, -1.98627295e-05],\n",
       "        [-3.60556063e-04,  2.20384081e-05, -7.03580445e-05, ...,\n",
       "          6.69088331e-05,  2.03141492e-04,  8.22270340e-06],\n",
       "        [-5.76338964e-04, -9.64547507e-05, -2.50624493e-04, ...,\n",
       "          1.74180896e-05,  1.25652077e-04,  2.09353704e-04],\n",
       "        ...,\n",
       "        [ 7.46255857e-04, -7.48863502e-04,  1.19099068e-03, ...,\n",
       "         -2.71784235e-03,  1.57258008e-03, -4.97166906e-03],\n",
       "        [ 6.95009774e-04, -8.13656545e-04,  1.24107010e-03, ...,\n",
       "         -2.89845048e-03,  1.62402005e-03, -5.19693177e-03],\n",
       "        [ 6.48321293e-04, -8.77142476e-04,  1.28517114e-03, ...,\n",
       "         -3.06468410e-03,  1.66976464e-03, -5.38893323e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47a76f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dbe829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "644/644 [==============================] - 274s 422ms/step - loss: 1.6805\n",
      "Epoch 2/10\n",
      "644/644 [==============================] - 273s 424ms/step - loss: 1.4057\n",
      "Epoch 3/10\n",
      "644/644 [==============================] - 273s 424ms/step - loss: 1.3232\n",
      "Epoch 4/10\n",
      "644/644 [==============================] - 274s 425ms/step - loss: 1.2579\n",
      "Epoch 5/10\n",
      "644/644 [==============================] - 274s 426ms/step - loss: 1.2017\n",
      "Epoch 6/10\n",
      "644/644 [==============================] - 275s 426ms/step - loss: 1.1511\n",
      "Epoch 7/10\n",
      "644/644 [==============================] - 274s 426ms/step - loss: 1.1045\n",
      "Epoch 8/10\n",
      "644/644 [==============================] - 274s 425ms/step - loss: 1.0612\n",
      "Epoch 9/10\n",
      "644/644 [==============================] - 274s 425ms/step - loss: 1.0212\n",
      "Epoch 10/10\n",
      "644/644 [==============================] - 274s 426ms/step - loss: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8701823a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "275bf6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        predict = model(test_tensor) \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b884fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you so much <end> '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6078ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i will never let you go <end> '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i will\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe579e",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<ul> 1. <strong>프로젝트 설명</strong>\n",
    "    <p> 노래 가사를 학습 데이터로 사용하여 모델을 학습시키고 노래 가사를 출력하는 딥러닝 모델을 만들어보았다.</p>\n",
    "</ul>\n",
    "<ul> 2. <strong>시도한 것들</strong>\n",
    "    <li> 데이터 전처리 전에 학습 데이터에 Hallelujah만 반복해서 출력되는 것을 확인하고 토큰의 개수를 1개 이상으로 조정하였다.</li>\n",
    "    <li> 노래 가사를 만드는게 목적이기 때문에 문장부호를 제외한 토큰의 개수를 15개 이하로 제한하였다.</li>\n",
    "</ul>\n",
    "<ul> 3. <strong>알게된 점</strong>\n",
    "    <li> 토큰을 15개 이하로 제한하는 과정에서 .split()을 sentence에 할 것인지 preprocessed_sentence에 할 것인지에 따라 데이터의 양이 달라졌다. 전처리 하기 전의 문장을 띄워쓰기 기준으로 나누면 문자열과 문장부호가 하나로 합쳐서 하나의 어절을 이룬다. 그러나 전처리 후의 문장을 띄워쓰기를 기준으로 끊으면 문장부호가 독립된 하나의 어절처럼 취급되어 토큰 15개가 넘어가는 경우가 있었다. 따라서 토큰 개수 제한을 하려는 상황에서는 전처리 전에 길이 제한을 하면 더 많은 데이터를 가지고 학습을 할 수 있다. </li>\n",
    "</ul>\n",
    "<ul> 4. <strong>어려웠던 점</strong>\n",
    "    <li> 자연어처리에서는 소스 문장, 타겟 문장을 각각 train data, test data로 사용하였다. 이와 관련하여 토큰화를 진행한 후 끝 단어 end를 없애면 소스 문장, 첫 단어 start를 없애면 타겟 문장으로 사용한다. 그런데 train data를 만들 때 end를 없애는게 아니라 pad일 수도 있는 마지막 토큰 하나를 제거한다. 왜 end를 제거하는 것이 아니라 토큰 길이만 하나 작은 데이터를 test data로 사용하는지 잘 모르겠다.</li>\n",
    "</ul>\n",
    "<ul> 5. <strong>자기 다짐</strong>\n",
    "    <li>RNN에서는 최종 입력되는 값이 결과값에 영향을 미치기 때문에 padding에서 pre방식이 더 유리하다고 한다. 이번 프로젝트에서는 padding을 문장 끝(post 방식)에 주었는데, 다음 번에는 문장 앞에 padding을 주면서 두 가지 결과를 비교해보는 것도 좋을 것 같다.</li>\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17c5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
